{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61ad7670-135a-4bcc-af80-19cce8398579",
   "metadata": {},
   "source": "# 1. Load prerequisites"
  },
  {
   "cell_type": "code",
   "id": "c77ec6f8-1b14-4d1e-a694-0660ab1e9f66",
   "metadata": {},
   "source": [
    "from utils import *\n",
    "\n",
    "import ipywidgets\n",
    "\n",
    "def get_image_network(device, dir_checkpoint, n_classes, in_size, image_gray, batch_img):\n",
    "    model = UMF_ConvLSTM(n_channels=1, n_classes=n_classes, bilinear=True, type_net=1)\n",
    "    model.load_state_dict(torch.load(dir_checkpoint))\n",
    "    model.eval()\n",
    "    model.to(device=device)\n",
    "\n",
    "    h, w = image_gray.shape\n",
    "    h_steps = setps_crop(h, in_size, 3)\n",
    "    w_steps = setps_crop(w, in_size, 3)\n",
    "    list_box = []\n",
    "    for i in h_steps:\n",
    "        for j in w_steps:\n",
    "            crop = [i, i + in_size, j, j + in_size]\n",
    "            list_box.append(crop)\n",
    "\n",
    "    n_crops = len(list_box)\n",
    "    n_reps = 1\n",
    "    f = 0\n",
    "    while f == 0:\n",
    "        if (batch_img * n_reps) < n_crops:\n",
    "            n_reps = n_reps + 1\n",
    "        else:\n",
    "            f = 1\n",
    "\n",
    "    if n_classes == 1:\n",
    "        masK_img = np.zeros((h, w), dtype=\"uint8\")\n",
    "\n",
    "    if n_classes == 4:\n",
    "        masK_img = np.zeros((h, w, 3), dtype=\"uint8\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        cnt_crops1 = 0\n",
    "        cnt_crops2 = 0\n",
    "        for i in range(n_reps):\n",
    "            masK_crops = np.zeros((h, w), dtype=\"uint8\")\n",
    "            for j in range(batch_img):\n",
    "                if cnt_crops1 < n_crops:\n",
    "                    image_i = image_gray[list_box[cnt_crops1][0]:list_box[cnt_crops1][1], list_box[cnt_crops1][2]:list_box[cnt_crops1][3]]\n",
    "                    image_i = np.expand_dims(image_i, axis=0)\n",
    "                    masK_crops = update_mask(masK_crops, image_i)\n",
    "                    cnt_crops1 = cnt_crops1 + 1\n",
    "\n",
    "            image_i = torch.from_numpy(masK_crops).to(device=device, dtype=torch.float32).unsqueeze(1)\n",
    "            image_i = model(image_i)\n",
    "            image_i = (torch.sigmoid(image_i) > 0.5) * 255\n",
    "            image_i = image_i.cpu().numpy().astype('uint8')\n",
    "\n",
    "            for j in range(batch_img):\n",
    "                if cnt_crops2 < n_crops:\n",
    "                    if n_classes == 1:\n",
    "                        masK_img[list_box[cnt_crops2][0]:list_box[cnt_crops2][1], list_box[cnt_crops2][2]:list_box[cnt_crops2][3]] = image_i[j, :, :, :]\n",
    "\n",
    "                    if n_classes == 4:\n",
    "                        masK_img[list_box[cnt_crops2][0]:list_box[cnt_crops2][1], list_box[cnt_crops2][2]:list_box[cnt_crops2][3], 0] = image_i[j, 1, :, :]\n",
    "                        masK_img[list_box[cnt_crops2][0]:list_box[cnt_crops2][1], list_box[cnt_crops2][2]:list_box[cnt_crops2][3], 1] = image_i[j, 2, :, :]\n",
    "                        masK_img[list_box[cnt_crops2][0]:list_box[cnt_crops2][1], list_box[cnt_crops2][2]:list_box[cnt_crops2][3], 2] = image_i[j, 3, :, :]\n",
    "                    cnt_crops2 = cnt_crops2 + 1\n",
    "\n",
    "    del model, image_i, masK_crops\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return masK_img\n",
    "\n",
    "checkpoint_SEG = os.path.join('Models', 'Body', 'SEG')\n",
    "checkpoint_SKL = os.path.join('Models', 'Body', 'SKL')\n",
    "network_SEG = os.path.join(checkpoint_SEG, 'model.pth')\n",
    "network_SKL = os.path.join(checkpoint_SKL, 'model.pth')\n",
    "from Models.Body.UMF_ConvLSTM import UMF_ConvLSTM\n",
    "\n",
    "print('Code block execution complete!')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0d6b8760-21b4-4544-a8b7-790b50934f12",
   "metadata": {},
   "source": "# 2. Activate input fields"
  },
  {
   "cell_type": "code",
   "id": "91c155f0-7396-4eb9-8ea3-752f1f9648e0",
   "metadata": {},
   "source": [
    "input_folder_widget = ipywidgets.Text(\n",
    "    value='',\n",
    "    placeholder='Please specify the full path of the folder with your images',\n",
    "    description='Input folder path:',\n",
    "    disabled=False,\n",
    "    continuous_update=True\n",
    ")\n",
    "\n",
    "output_folder_widget= ipywidgets.Text(\n",
    "    value='',\n",
    "    placeholder='Please specify the full path of your output folder',\n",
    "    description='Output folder path (will be created if needed):',\n",
    "    disabled=False,\n",
    "    continuous_update=True\n",
    ")\n",
    "\n",
    "file_extension_widget= ipywidgets.Text(\n",
    "    value='',\n",
    "    placeholder='Please specify the file extension of your images',\n",
    "    description='Image file extension:',\n",
    "    disabled=False,\n",
    "    continuous_update=True\n",
    ")\n",
    "\n",
    "\n",
    "batch_crop_widget=ipywidgets.IntSlider(\n",
    "    value=9,\n",
    "    min=4,\n",
    "    max=16,\n",
    "    step=1,\n",
    "    description='Batch crop images:',\n",
    "    disabled=False,\n",
    "    continuous_update=True,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "\n",
    "parallel_process_button=ipywidgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Keep checked for parallel processing',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "n_process_widget=ipywidgets.IntSlider(\n",
    "    value=4,\n",
    "    min=2,\n",
    "    max=16,\n",
    "    step=1,\n",
    "    description='Number of parallel processes to run:',\n",
    "    disabled=False,\n",
    "    continuous_update=True,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "\n",
    "display(input_folder_widget)\n",
    "display(output_folder_widget)\n",
    "display(file_extension_widget)\n",
    "display(batch_crop_widget)\n",
    "display(parallel_process_button)\n",
    "display(n_process_widget)\n",
    "\n",
    "print('Code block execution complete!')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "30311147-5045-45c8-96ae-bc72cff72a59",
   "metadata": {},
   "source": [
    "## Please fill in the ^above^ input fields before activating the next code cells."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. Read user inputs",
   "id": "5c82b670570e4f81"
  },
  {
   "cell_type": "code",
   "id": "e1cc4509-8150-4cac-89ab-7a27eea39745",
   "metadata": {},
   "source": [
    "test_images = input_folder_widget.value\n",
    "print('Input folder:', test_images)\n",
    "\n",
    "save_dir = output_folder_widget.value\n",
    "if not os.path.exists(save_dir):\n",
    "   os.makedirs(save_dir)\n",
    "    \n",
    "print('Output:', save_dir)\n",
    "\n",
    "end_gray_image = file_extension_widget.value\n",
    "print('Extension:', end_gray_image)\n",
    "\n",
    "batch_crop_img = batch_crop_widget.value\n",
    "print('Image sub-crops:', batch_crop_img)\n",
    "\n",
    "Parallel_process = parallel_process_button.value\n",
    "print('Parallel processing:', Parallel_process)\n",
    "\n",
    "N_process = n_process_widget.value\n",
    "if Parallel_process== True: \n",
    "    print('Number of processes:', N_process)\n",
    "\n",
    "print('Code block execution complete!')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ab18b11c-4bbf-45fb-9538-18ba4cf1bc39",
   "metadata": {},
   "source": "### The ^above^ readout should confirm your inputs"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4. Begin Evaluation",
   "id": "3493377f2cf37d66"
  },
  {
   "cell_type": "code",
   "id": "432adf69-25ef-477a-b766-96116057a179",
   "metadata": {},
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "path_SKELETON = os.path.join(save_dir,'0_SKELETON/')\n",
    "path_SEGMENTATION = os.path.join(save_dir,'0_SEGMENTATION/')\n",
    "\n",
    "if not os.path.exists(path_SKELETON):\n",
    "    os.makedirs(path_SKELETON)\n",
    "\n",
    "if not os.path.exists(path_SEGMENTATION):\n",
    "    os.makedirs(path_SEGMENTATION)\n",
    "\n",
    "list_images = sorted(list_files(test_images, end_gray_image))\n",
    "\n",
    "with tqdm(total=len(list_images), unit='img') as pbar:\n",
    "    for name_image in list_images:\n",
    "        # name_image = list_images[q]\n",
    "        name_image_ = name_image.split('.')[0]\n",
    "        name_image_save = name_image_ + '.bmp'\n",
    "        path_image_gray = os.path.join(test_images, name_image)\n",
    "\n",
    "        image_gray = np.asarray(Image.open(path_image_gray))  # read gray image\n",
    "        if len(image_gray.shape) > 2:\n",
    "            image_gray = cv2.cvtColor(image_gray, cv2.COLOR_BGR2GRAY)\n",
    "        h, w = image_gray.shape\n",
    "\n",
    "        if not os.path.exists(os.path.join(path_SEGMENTATION, name_image_save)):\n",
    "            # Obtain segmentation from Network1\n",
    "            image_seg = get_image_network(device=device, dir_checkpoint=network_SEG, n_classes=4,\n",
    "                                            in_size=512, image_gray=image_gray, batch_img=batch_crop_img)\n",
    "\n",
    "            # Obtain Skeleton from Network2\n",
    "            image_skl = get_image_network(device=device, dir_checkpoint=network_SKL, n_classes=1,\n",
    "                                            in_size=512, image_gray=image_gray, batch_img=batch_crop_img)\n",
    "            cv2.imwrite(os.path.join(path_SEGMENTATION, name_image_save), image_seg)\n",
    "            cv2.imwrite(os.path.join(path_SKELETON, name_image_save), image_skl)\n",
    "        else:\n",
    "            image_seg = cv2.imread(os.path.join(path_SEGMENTATION, name_image_save))\n",
    "            image_skl = cv2.imread(os.path.join(path_SKELETON, name_image_save), cv2.IMREAD_GRAYSCALE)\n",
    "        pbar.update(1)\n",
    "\n",
    "print('Code block execution complete!')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5. Post processing",
   "id": "def54e2f6faab2cd"
  },
  {
   "cell_type": "code",
   "id": "5b68e733-2670-4dcc-b55f-d4345c7794a1",
   "metadata": {},
   "source": [
    "area_percentage = 60\n",
    "area_min = 600\n",
    "kernel_size = 3\n",
    "angle_value = 20\n",
    "\n",
    "path_summary_save = '0_summary_results'\n",
    "path_complete_mask = '1_complete_mask'\n",
    "path_edge_small_mask = '1_edge_small_mask'\n",
    "path_overlap_mask = '1_overlap_mask'\n",
    "path_all_rois_results = '1_all_rois_results'\n",
    "\n",
    "\n",
    "path_summary_save = os.path.join(save_dir, path_summary_save)\n",
    "path_complete_mask = os.path.join(save_dir, path_complete_mask)\n",
    "path_edge_small_mask = os.path.join(save_dir, path_edge_small_mask)\n",
    "path_overlap_mask = os.path.join(save_dir, path_overlap_mask)\n",
    "\n",
    "print('Folder complete mask:', path_complete_mask)\n",
    "print('Folder edge and small mask:', path_edge_small_mask)\n",
    "print('Folder overlap masks:', path_overlap_mask)\n",
    "print('Folder save_results:', path_summary_save)\n",
    "\n",
    "import numpy as np\n",
    "from skimage import measure\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "args = {'Parallel_process': Parallel_process,\n",
    "        'path_images': test_images,\n",
    "        'path_SEGMENTATION': path_SEGMENTATION,\n",
    "        'path_SKELETON': path_SKELETON,\n",
    "        'path_complete_mask': path_complete_mask,\n",
    "        'path_edge_small_mask': path_edge_small_mask,\n",
    "        'path_overlap_mask': path_overlap_mask,\n",
    "        'path_summary_save': path_summary_save,\n",
    "        'area_percentage': area_percentage,\n",
    "        'area_min': area_min,\n",
    "        'kernel_size': kernel_size,\n",
    "        'angle_value': angle_value\n",
    "        }\n",
    "\n",
    "def post_processing(args, name_image):\n",
    "    name_image_ = name_image.split('.')[0]\n",
    "    name_image_save = name_image_ + '.bmp'\n",
    "    seg_path=os.path.join(args['path_SEGMENTATION'], name_image_save)\n",
    "    image_seg = cv2.imread(seg_path)\n",
    "\n",
    "    save_path = os.path.join(args['path_summary_save'], name_image_) + '.png'\n",
    "    if not os.path.exists(save_path):\n",
    "        skl_path=os.path.join(args['path_SKELETON'], name_image_save)\n",
    "        image_skl = cv2.imread(skl_path)\n",
    "        image_skl = (cv2.cvtColor(image_skl, cv2.COLOR_BGR2GRAY) > 0) * 255\n",
    "\n",
    "        area_min = args['area_min']\n",
    "        angle_value = args['angle_value']\n",
    "        kernel_size = args['kernel_size']\n",
    "        area_percentage = args['area_percentage']\n",
    "\n",
    "        path_images = args['path_images']\n",
    "        path_complete_mask = args['path_complete_mask']\n",
    "        path_edge_small_mask = args['path_edge_small_mask']\n",
    "        path_overlap_mask = args['path_overlap_mask']\n",
    "        path_summary_save = args['path_summary_save']\n",
    "\n",
    "        if not os.path.exists(path_complete_mask):\n",
    "            try:\n",
    "              os.makedirs(path_complete_mask)\n",
    "            except FileExistsError:\n",
    "              pass\n",
    "\n",
    "        if not os.path.exists(path_edge_small_mask):\n",
    "            try:\n",
    "              os.makedirs(path_edge_small_mask)\n",
    "            except FileExistsError:\n",
    "              pass\n",
    "\n",
    "        if not os.path.exists(path_overlap_mask):\n",
    "            try:\n",
    "              os.makedirs(path_overlap_mask)\n",
    "            except FileExistsError:\n",
    "              pass\n",
    "\n",
    "        if not os.path.exists(path_summary_save):\n",
    "            try:\n",
    "              os.makedirs(path_summary_save)\n",
    "            except FileExistsError:\n",
    "              pass\n",
    "\n",
    "\n",
    "        # ***************** Improve edge detection ****************************************************\n",
    "        edge_final = check_edge_worms(image_seg, kernel_size)\n",
    "\n",
    "        # ***************** none overlappings and overlappings *******************************************\n",
    "        none_overlappings, overlapping = obtain_overlappings(image_seg, edge_final, kernel_size + 2)\n",
    "        labels_overlapping = measure.label(overlapping, background=0)\n",
    "        labels_none_overlapping = measure.label(none_overlappings, background=0)\n",
    "\n",
    "        # ************************** None-overlappings ***************************************************\n",
    "        true_overlaps = check_overlapping(labels_overlapping, labels_none_overlapping)\n",
    "        mask_worms = get_none_overlapping(labels_none_overlapping, true_overlaps, area_min, kernel_size)  # none-overl\n",
    "        mask_worms_Dims = worms2NDims(mask_worms, kernel_size + 2)  # each dimension is a worm\n",
    "        results_masks_NO = check_noneOverlapping(mask_worms_Dims, area_percentage)  # Check good/bad masks\n",
    "\n",
    "        # ************************** overlappings ********************************************************\n",
    "        mask_overlaps_Dims = overlapping_worms(true_overlaps, mask_worms, labels_overlapping,\n",
    "                                               labels_none_overlapping, image_skl, area_min,\n",
    "                                               kernel_size+2, angle_value)\n",
    "\n",
    "        # ***************************** Save imgs results *****************************************************\n",
    "        name_image_final = os.path.join(path_summary_save, name_image_) + '.png'\n",
    "        path_image_gray = os.path.join(path_images, name_image)\n",
    "        image_gray = imread_image(path_image_gray)  # read gray image\n",
    "        if len(image_gray.shape) > 2:\n",
    "            image_gray = cv2.cvtColor(image_gray, cv2.COLOR_BGR2GRAY)\n",
    "        save_results_mask(name_image_final, image_gray, results_masks_NO, mask_overlaps_Dims, 1)  # RGB\n",
    "        complete_mask_name = os.path.join(path_complete_mask, name_image)\n",
    "        save_mask_tif(complete_mask_name, results_masks_NO['worms_good'])\n",
    "        edge_small_mask_name= os.path.join(path_edge_small_mask,name_image)\n",
    "        save_mask_tif(edge_small_mask_name, results_masks_NO['worms_bads'])\n",
    "        overlap_mask_name=os.path.join(path_overlap_mask, name_image)\n",
    "        save_mask_tif(overlap_mask_name, mask_overlaps_Dims)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\".*OME series cannot handle discontiguous storage\")\n",
    "\n",
    "if Parallel_process:\n",
    "    Parallel(n_jobs=N_process, verbose=1, backend='multiprocessing')(\n",
    "        delayed(post_processing)(args, name_image) for name_image in list_images)\n",
    "else:\n",
    "    with tqdm(total=len(list_images), unit='img') as pbar:\n",
    "        for name_image in list_images:\n",
    "            post_processing(args, name_image)\n",
    "            pbar.update(1)\n",
    "\n",
    "## Show results masks\n",
    "for name_image_showed in list_images:\n",
    "  name_image_ = name_image_showed.split('.')[0]\n",
    "  name_image_result = os.path.join(path_summary_save, name_image_) + '.png'\n",
    "  image_result = cv2.imread(name_image_result)\n",
    "\n",
    "  plt.figure(figsize=(15, 15))\n",
    "  plt.imshow(image_result)\n",
    "  fig = plt.gcf()\n",
    "  fig.set_size_inches(12, 12)\n",
    "  plt.show()\n",
    "\n",
    "## Save all ROIS together.\n",
    "\n",
    "path_all_rois_results = os.path.join(save_dir, path_all_rois_results)\n",
    "\n",
    "from utils import list_files, save_mask_rois\n",
    "if not os.path.exists(path_all_rois_results):\n",
    "    os.makedirs(path_all_rois_results)\n",
    "\n",
    "list_images = sorted(list_files(test_images, end_gray_image))\n",
    "with tqdm(total=len(list_images), unit='img') as pbar:\n",
    "    for name_image in list_images:\n",
    "        path_good_mask = os.path.join(path_complete_mask, name_image)\n",
    "        print(path_good_mask)\n",
    "        image_good_mask = read_tiff_mask(path_good_mask)\n",
    "        path_overlap_mask_mask=os.path.join(path_overlap_mask, name_image)\n",
    "        print(path_overlap_mask_mask)\n",
    "        image_overlap_mask = read_tiff_mask(path_overlap_mask_mask)\n",
    "        path_reject_mask=os.path.join(path_edge_small_mask, name_image)\n",
    "        print(path_reject_mask)\n",
    "        image_reject_mask = read_tiff_mask(path_reject_mask)\n",
    "        name_image_ = name_image.split('.')[0]\n",
    "        image_total_mask=np.concatenate((image_good_mask,image_overlap_mask,image_reject_mask),axis=0)\n",
    "        name_zip_save = name_image_ + '.zip'\n",
    "        path_zip_save = os.path.join(path_all_rois_results, name_zip_save)\n",
    "        save_mask_rois(path_zip_save, image_total_mask)\n",
    "        pbar.update(1)\n",
    "\n",
    "print('Code block execution complete!')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4f1cc025-bcfe-479d-bab2-fd353367bbfa",
   "metadata": {},
   "source": "# 6. Activate the curation correction inputs"
  },
  {
   "cell_type": "code",
   "id": "c85c807d-2ed3-414a-af1d-cea297dbe4de",
   "metadata": {},
   "source": [
    "target_image_widget= ipywidgets.Text(\n",
    "    value='',\n",
    "    placeholder='Please specify the name (with file extension) of the image you wish to correct.',\n",
    "    description='Image to correct:',\n",
    "    disabled=False,\n",
    "    continuous_update=True\n",
    ")\n",
    "\n",
    "desired_worms_widget= ipywidgets.Text(\n",
    "    value='',\n",
    "    placeholder='Please specify the masks you want to keep, seperated by commas',\n",
    "    description='Masks to keep:',\n",
    "    disabled=False,\n",
    "    continuous_update=True\n",
    ")\n",
    "\n",
    "display(target_image_widget)\n",
    "display(desired_worms_widget)\n",
    "\n",
    "print('Code block execution complete!')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 7. Fill in the above forms and run the following code block to implement corrections in the segmentation curation. You can run it again for different images.",
   "id": "0434f7e0-5b2c-46e4-8fa7-69fc5cf8326b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "name_image_change = target_image_widget.value\n",
    "print('Image selected:', name_image_change)\n",
    "index_images = desired_worms_widget.value\n",
    "\n",
    "image_complete_mask_path = os.path.join(path_complete_mask, name_image_change)\n",
    "image_edge_small_mask_path =os.path.join(path_edge_small_mask, name_image_change)\n",
    "\n",
    "image_complete_mask_before = read_tiff_mask(image_complete_mask_path)\n",
    "image_edge_small_mask_before = read_tiff_mask(image_edge_small_mask_path)\n",
    "\n",
    "masK_predict_all = np.concatenate((image_complete_mask_before, image_edge_small_mask_before), axis=0)\n",
    "\n",
    "try:\n",
    "  image_overlap_mask = os.path.join(path_overlap_mask, name_image_change)\n",
    "  image_overlap_mask = read_tiff_mask(image_overlap_mask)\n",
    "  masK_predict_all = np.concatenate((masK_predict_all, image_overlap_mask), axis=0)\n",
    "except:\n",
    "  rt = -1\n",
    "\n",
    "\n",
    "all_elements = []\n",
    "for i in range(1, masK_predict_all.shape[0] + 1):\n",
    "    all_elements.append(str(i))\n",
    "\n",
    "index_images = index_images.split(',')\n",
    "\n",
    "all_elements = all_elements + index_images\n",
    "\n",
    "index_bad = [i for i in all_elements if all_elements.count(i) == 1]\n",
    "print('Worms good: ', index_images)\n",
    "print('Worms bad: ', index_bad)\n",
    "worms_true = np.zeros((len(index_images), masK_predict_all.shape[1], masK_predict_all.shape[2]), np.int8)\n",
    "for i in range(len(index_images)):\n",
    "    index = int(index_images[i])\n",
    "    worms_true[i, :, :] = masK_predict_all[index - 1, :, :]\n",
    "\n",
    "\n",
    "worms_bad = np.zeros((len(index_bad), masK_predict_all.shape[1], masK_predict_all.shape[2]), np.int8)\n",
    "for i in range(len(index_bad)):\n",
    "    index = int(index_bad[i])\n",
    "    worms_bad[i, :, :] = masK_predict_all[index - 1, :, :]\n",
    "\n",
    "worms_true = (worms_true != 0) * 255\n",
    "worms_bad = (worms_bad != 0) * 255\n",
    "\n",
    "worms_all_true, new_map = Ndims2image(worms_true, 1)\n",
    "worms_all_bad, _ = Ndims2image(worms_bad, 1)\n",
    "\n",
    "centroid_predict_true, label_predict_true = get_centroid(worms_true, 1)\n",
    "centroid_predict_bad, label_predict_bad = get_centroid(worms_bad, len(index_images))\n",
    "\n",
    "\n",
    "tifffile.imwrite(image_complete_mask_path, worms_true.astype(np.uint8))\n",
    "tifffile.imwrite(image_edge_small_mask_path, worms_bad.astype(np.uint8))\n",
    "try:\n",
    "  os.remove(os.path.join(path_overlap_mask, name_image_change))\n",
    "except:\n",
    "  print('Overlap masks do not exist here')\n",
    "\n",
    "\n",
    "path_image_gray = os.path.join(test_images, name_image_change)\n",
    "image_gray = imread_image(path_image_gray)  # read gray image\n",
    "if len(image_gray.shape) > 2:\n",
    "    image_gray = cv2.cvtColor(image_gray, cv2.COLOR_BGR2GRAY)\n",
    "worms_all, new_map = Ndims2image(masK_predict_all, 1)\n",
    "\n",
    "# show images results\n",
    "font = {'family': 'serif',\n",
    "        'color': 'white',\n",
    "        'weight': 'bold',\n",
    "        'size': 8,\n",
    "        }\n",
    "\n",
    "bbox = {'facecolor': 'black',\n",
    "        'edgecolor': 'red',\n",
    "        'linewidth': 2\n",
    "        }\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "ax1 = fig.add_subplot(221)\n",
    "ax1.title.set_text('Gray image')\n",
    "ax1.imshow(image_gray, cmap='gray', vmin=0, vmax=255)\n",
    "\n",
    "ax2 = fig.add_subplot(222)\n",
    "ax2.title.set_text('All masks')\n",
    "ax2.imshow(worms_all, cmap=new_map, interpolation='None')\n",
    "\n",
    "ax3 = fig.add_subplot(223)\n",
    "ax3.title.set_text('Complete masks')\n",
    "ax3.imshow(worms_all_true, cmap=new_map, interpolation='None')\n",
    "for i in range(len(centroid_predict_true)):\n",
    "    ax3.text(centroid_predict_true[i][1], centroid_predict_true[i][0], label_predict_true[i], fontdict=font, bbox=bbox)\n",
    "\n",
    "ax4 = fig.add_subplot(224)\n",
    "ax4.title.set_text('Edge, small and overlap mask')\n",
    "ax4.imshow(worms_all_bad, cmap=new_map, interpolation='None')\n",
    "for i in range(len(centroid_predict_bad)):\n",
    "    ax4.text(centroid_predict_bad[i][1], centroid_predict_bad[i][0], label_predict_bad[i], fontdict=font, bbox=bbox)\n",
    "\n",
    "name_image_change_ = name_image_change.split('.')[0]\n",
    "name_image_result = os.path.join(path_summary_save, name_image_change_) + 'Corrected.jpg'\n",
    "plt.savefig(name_image_result)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12, 12)\n",
    "\n",
    "print('Code block execution complete!')"
   ],
   "id": "1256df9b-d087-4cad-9a4d-fd94ae3670e3"
  },
  {
   "cell_type": "markdown",
   "id": "a3ebff02-de27-4009-8283-fefbb875eb4b",
   "metadata": {},
   "source": "### Run the previous block again with different inputs to correct more images or run the last block after finishing all corrections to recieve the final curated results and ROI files."
  },
  {
   "cell_type": "markdown",
   "id": "3c7dc1a8-aef2-4c97-9299-fe14bbaa0fce",
   "metadata": {},
   "source": "# 8. Save curated segmentations as ImageJ ROIs."
  },
  {
   "cell_type": "code",
   "id": "7d57f9cb-a9da-45b0-a0b3-e55e1cd882e7",
   "metadata": {},
   "source": [
    "folder_rois_results = '2_curated_rois_results'\n",
    "folder_rois_results = os.path.join(save_dir, folder_rois_results)\n",
    "print(folder_rois_results)\n",
    "\n",
    "from utils import list_files, save_mask_rois\n",
    "if not os.path.exists(folder_rois_results):\n",
    "    os.makedirs(folder_rois_results)\n",
    "\n",
    "list_images = sorted(list_files(path_complete_mask, end_gray_image))\n",
    "with tqdm(total=len(list_images), unit='img') as pbar:\n",
    "    for name_image in list_images:\n",
    "        image_good_mask = os.path.join(path_complete_mask, name_image)\n",
    "        image_good_mask = read_tiff_mask(image_good_mask)\n",
    "        name_image_ = name_image.split('.')[0]\n",
    "        name_zip_save = os.path.join(folder_rois_results, name_image_) + '.zip'\n",
    "        save_mask_rois(name_zip_save, image_good_mask)\n",
    "        pbar.update(1)\n",
    "\n",
    "print('Code block execution complete!')"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
